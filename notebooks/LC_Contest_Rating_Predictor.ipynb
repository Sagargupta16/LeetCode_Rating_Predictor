{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP891Zwc4h/QxO5uTRB0lwp",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Sagargupta16/LeetCode_Rating_Predictor/blob/main/LC_Contest_Rating_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": "import json\nimport numpy as np\nimport tensorflow as tf\nimport joblib\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# Paths (relative to project root)\nROOT = Path(\"..\") if Path(\"../data/data.json\").exists() else Path(\".\")\nDATA_PATH = ROOT / \"data\" / \"data.json\"\nMODEL_PATH = ROOT / \"model.keras\"\nSCALER_PATH = ROOT / \"scaler.save\"\n\n# Number of features must match production (main.py)\nNUM_FEATURES = 7\n\nprint(f\"TensorFlow {tf.__version__}\")\ngpus = tf.config.list_physical_devices(\"GPU\")\nif gpus:\n    print(f\"GPU detected: {gpus[0].name}\")\n    # Allow memory growth to avoid OOM on small GPUs\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\nelse:\n    print(\"No GPU detected â€” training on CPU\")\n    print(\"  For GPU on Windows: use WSL2 + pip install 'tensorflow[and-cuda]'\")\n    print(\"  Model is small (3K params) so CPU training takes ~80 seconds\")\nprint(f\"Data path: {DATA_PATH.resolve()}\")",
   "metadata": {
    "id": "r9DxuNQ9r_vI",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "outputId": "a20ac844-5905-489c-c58b-0d1e3e0b4b25"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "UKlWkOAAlK5q"
   },
   "outputs": [],
   "source": "## Data Collection\n\n**Skip cells 2-4 if you already have `data/data.json`.**\n\nTo refresh training data, run from the project root:\n```bash\npython scripts/update_data.py\n```\nThe REST contest API is now blocked (403), so data collection uses GraphQL via `scripts/update_data.py`."
  },
  {
   "cell_type": "markdown",
   "source": "*(Data collection cells removed -- use `python scripts/update_data.py` instead)*",
   "metadata": {
    "id": "rI0pFAlC0DpZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Load and Prepare Data\n\n7 features used in both training and production (`main.py`):\n\n| # | Feature | Source | Correlation |\n|---|---------|--------|-------------|\n| 1 | current_rating | input1 | -0.148 |\n| 2 | rank | input2 | -0.474 |\n| 3 | total_participants | input3 | -0.308 |\n| 4 | rank_percentage | input4 * 100 | -0.495 |\n| 5 | attended_contests | input5 | -0.115 |\n| 6 | log_rank | log(1 + rank) | **-0.508** |\n| 7 | rating_x_percentile | rating * percentile | **-0.555** |\n\nFeatures 6-7 are engineered from existing data and provide the strongest signal.",
   "metadata": {
    "id": "p4SQazsrrQ4J",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6f90a829-fa78-4e4f-9545-471e16d62ba9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load training data\nrecords = []\nwith open(DATA_PATH) as f:\n    for line in f:\n        records.append(json.loads(line))\nprint(f\"Loaded {len(records)} records\")\n\n# Extract raw fields\ninput1 = np.array([r[\"input1\"] for r in records])  # current_rating\ninput2 = np.array([r[\"input2\"] for r in records])  # rank\ninput3 = np.array([r[\"input3\"] for r in records])  # total_participants\ninput4 = np.array([r[\"input4\"] for r in records])  # percentile (0-1)\ninput5 = np.array([r[\"input5\"] for r in records])  # attended_contests\ny = np.array([r[\"output\"] for r in records])        # rating_change\n\n# Build 7-feature matrix matching production main.py\nrank_percentage = input4 * 100  # production computes rank*100/participants\nlog_rank = np.log1p(input2)\nrating_x_pct = input1 * input4\n\nX = np.column_stack([\n    input1,          # 0: current_rating\n    input2,          # 1: rank\n    input3,          # 2: total_participants\n    rank_percentage, # 3: rank_percentage\n    input5,          # 4: attended_contests\n    log_rank,        # 5: log(1 + rank)\n    rating_x_pct,    # 6: rating * percentile\n])\n\nassert X.shape[1] == NUM_FEATURES, f\"Expected {NUM_FEATURES} features, got {X.shape[1]}\"\nprint(f\"Feature matrix: {X.shape}\")\nprint(f\"Output: mean={y.mean():.2f}, std={y.std():.2f}\")\n\n# Scale features\nscaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)\njoblib.dump(scaler, SCALER_PATH)\nprint(f\"Scaler saved to {SCALER_PATH} ({NUM_FEATURES} features)\")\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.1, random_state=SEED\n)\nprint(f\"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGW-Rsbs1Ydm",
    "outputId": "65a788af-45a2-47bc-e427-8eeca7076f36"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Dense network (LSTM with 1 timestep adds overhead for zero benefit)\nmodel = Sequential([\n    Dense(64, activation=\"relu\", input_shape=(NUM_FEATURES,)),\n    Dropout(0.2),\n    Dense(32, activation=\"relu\"),\n    Dropout(0.2),\n    Dense(16, activation=\"relu\"),\n    Dense(1),\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"mse\",\n    metrics=[\"mae\"],\n)\nmodel.summary()\n\nearly_stop = EarlyStopping(\n    monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=1\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_split=0.1,\n    epochs=200,\n    batch_size=64,\n    callbacks=[early_stop],\n    verbose=1,\n)\n\n# Evaluate\ntest_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"\\nTest MSE:  {test_loss:.2f}\")\nprint(f\"Test RMSE: {np.sqrt(test_loss):.2f}\")\nprint(f\"Test MAE:  {test_mae:.2f}\")\n\nmodel.save(MODEL_PATH)\nprint(f\"Model saved to {MODEL_PATH}\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5RLpNU0wVLm",
    "outputId": "9e94cd83-cb0c-42c4-881e-cf7ab52f84fe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Sanity check: predict for a sample user\nrating, rank, participants, attended = 1957, 1869, 21165, 87\npct = (rank * 100) / participants\nsample = np.array([[rating, rank, participants, pct, attended, np.log1p(rank), rating * (rank / participants)]])\npred = model.predict(scaler.transform(sample), verbose=0)\n\nprint(f\"Rating: {rating}, Rank: {rank}/{participants}, Attended: {attended}\")\nprint(f\"Predicted change: {pred[0][0]:+.2f}\")\nprint(f\"Predicted new rating: {rating + pred[0][0]:.2f}\")\n\n# Training curve\ntry:\n    import matplotlib\n    matplotlib.use(\"Agg\")\n    import matplotlib.pyplot as plt\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    ax1.plot(history.history[\"loss\"], label=\"Train\")\n    ax1.plot(history.history[\"val_loss\"], label=\"Validation\")\n    ax1.set_xlabel(\"Epoch\"); ax1.set_ylabel(\"MSE\"); ax1.set_title(\"Loss\"); ax1.legend()\n\n    ax2.plot(history.history[\"mae\"], label=\"Train\")\n    ax2.plot(history.history[\"val_mae\"], label=\"Validation\")\n    ax2.set_xlabel(\"Epoch\"); ax2.set_ylabel(\"MAE\"); ax2.set_title(\"Mean Absolute Error\"); ax2.legend()\n\n    plt.tight_layout()\n    plt.show()\nexcept ImportError:\n    print(\"matplotlib not installed, skipping plot\")",
   "metadata": {
    "id": "YCtog77Yesm4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "513b5d75-052a-4a9c-f437-a62bf4a7e6da"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}